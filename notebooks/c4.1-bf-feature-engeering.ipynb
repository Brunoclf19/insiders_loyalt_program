{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6835c3-cb2b-4b3e-accb-c71a1bd46ee5",
   "metadata": {},
   "source": [
    "# PA005: High Value Custumer Identification (Insiders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e811937",
   "metadata": {},
   "source": [
    "## Ciclo 1 - Métricas de Validação de Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64cd92",
   "metadata": {},
   "source": [
    "1. Feature Engeneering\n",
    "  - Recência\n",
    "  - Frequência\n",
    "  - Monitary\n",
    "\n",
    "2. Métricas de validação de Clusterização\n",
    "  - WSS (Within-Cluster Sum of Square)\n",
    "  - SS (Silhouette Score)\n",
    "\n",
    "3. Cluster Analysis\n",
    "  - Plot 3D\n",
    "  - Cluster Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4090b",
   "metadata": {},
   "source": [
    "## Ciclo 2 - Análise de Silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8a9a7",
   "metadata": {},
   "source": [
    "1. Feature Engeneering\n",
    "  - Ticket Médio\n",
    "\n",
    "2. Análise de Silhouette\n",
    "  - Silhouette Analysis\n",
    "\n",
    "3. Cluster Validation\n",
    "  - UMAP\n",
    "\n",
    "4. Cluster Análise de Perfil\n",
    "  - Descrição dos centróisdes dos clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26aa9cf",
   "metadata": {},
   "source": [
    "## Ciclo 3 - Statistical Descriptive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c2f57",
   "metadata": {},
   "source": [
    "1. Análise Descritiva\n",
    "  - Atributos numéricos\n",
    "  - Atributos categóricos\n",
    "\n",
    "2. Features Engeneering\n",
    "  - Recência média\n",
    "  - Número de Retornos (Devoluções)\n",
    "\n",
    "3. Data Preparation (Encoding)\n",
    "  - Standard Scaler and MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4076a6c-fb27-404c-be59-5ec6ffa9167b",
   "metadata": {},
   "source": [
    "# 0.0 Planejamento da solução (IOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0fe713",
   "metadata": {},
   "source": [
    "### Input - Entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086ea42",
   "metadata": {},
   "source": [
    "1. Problema de Negócio\n",
    "  - Selecionar os clientes mais valiosos para integrar um programa de fidelização\n",
    "2. Conjunto de dados\n",
    "  - Vendas de um Ecommerce Online, durante o período de um ano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed536b",
   "metadata": {},
   "source": [
    "### Output - Saída"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcdeb5a",
   "metadata": {},
   "source": [
    "1. Indicação das pessoas que farão parte do programa Insiders\n",
    "  - Lista: client_id | is_insider\n",
    "\n",
    "2. Relatório com as respostas das perguntas de negócio.\n",
    "  - Quem são as pessoas elegíveis para participar do programa de Insiders?\n",
    "  - Quantos clientes farão parte do grupo?\n",
    "  - Quais as principais características desse clientes?\n",
    "  - Qual a porcentagem de contribuição do faturamento desses clientes, vinda do Insiders?\n",
    "  - Qual a expectativa de faturamento desse grupo para os próximos meses?\n",
    "  - Quais as condições para uma pessoa ser elegível ao Insiders?\n",
    "  - Quais as condições para uma pessoa ser removida do Insiders?\n",
    "  - Qual a garantia que o programa Insiders é melhor que o restante da base?\n",
    "  - Quais ações o time de marketing pode realizar para aumentar o faturamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b2072",
   "metadata": {},
   "source": [
    "### Tasks - Tarefas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8f74c",
   "metadata": {},
   "source": [
    "1. Quem são as pessoas elegíveis para participar do programa de Insiders?\n",
    "  - O que é ser elegível? O que são clientes de maior \"valor\"?\n",
    "  - Faturamento:\n",
    "    - Alto Ticket Médio\n",
    "    - Alto LTV (Life Time Value - Gasto durante seu período de vida na empresa)\n",
    "    - Baixo Recência\n",
    "    - Alto basket size (tamanho da cesta de compra)\n",
    "    - Baixa probabilidade de churn (parou de comprar)\n",
    "    - Alta previsão LTV\n",
    "    - Alta previsão de compra\n",
    "\n",
    "  - Custo\n",
    "    - Baixa taxa de devolução\n",
    "\n",
    "  - Experiência de Compra\n",
    "    - Média alta das avaliações\n",
    "\n",
    "2. Quantos clientes farão parte do grupo?\n",
    "  - Número total de clientes\n",
    "  - Calcula a % do grupo Insiders\n",
    "\n",
    "3. Quais as principais características desse clientes?\n",
    "  - Escrever características do cliente\n",
    "    - Idade\n",
    "    - Localização\n",
    "    \n",
    "  - Ecrever características de consumo\n",
    "    - Atributos da clusterização (perfil de compra do cliente)\n",
    "\n",
    "4. Qual a porcentagem de contribuição do faturamento desses clientes, vinda do Insiders?\n",
    "  - Faturamento total do ano\n",
    "  - Faturamento do grupo Insiders\n",
    "\n",
    "5. Qual a expectativa de faturamento desse grupo para os próximos meses?\n",
    "  - LTV do grupo Insiders\n",
    "  - Análise de Cohort (Marcação da pessoa, como por exemplo no tempo, perfil de pessoas que entraram no mesmo mês)\n",
    "\n",
    "6. Quais as condições para uma pessoa ser elegível ao Insiders?\n",
    "  - Definir a periodicidade (recorrência de rodar o modelo)\n",
    "  - A pessoa precisa ser similar ou parecida com uma pessoa do grupo\n",
    "\n",
    "7. Quais as condições para uma pessoa ser removida do Insiders?\n",
    "  - Definir a periodicidade (recorrência de rodar o modelo)\n",
    "  - A pessoa precisa ser disimilar ou s distanciar das médias do grupo\n",
    "\n",
    "8. Qual a garantia que o programa Insiders é melhor que o restante da base?\n",
    "  - Teste A/B\n",
    "  - Teste A/B Baysiano\n",
    "  - Teste de hipóteses\n",
    "  \n",
    "9. Quais ações o time de marketing pode realizar para aumentar o faturamento?\n",
    "  - Desconto\n",
    "  - Preferência de compra\n",
    "  - Frete\n",
    "  - Visita a empresa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638665b",
   "metadata": {},
   "source": [
    "## Benchmark de soluções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d8f5c",
   "metadata": {},
   "source": [
    "### 1. Desk Research - Pesquisa de soluções das outras empresas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ea79c",
   "metadata": {},
   "source": [
    "- Modelo RFM\n",
    "  1. Recência\n",
    "    a. Tempo desde a última compra\n",
    "    b. Responsividade\n",
    "\n",
    "  2. Frequência\n",
    "    a. Quantidade de compras em um período\n",
    "    b. Engajamento\n",
    "\n",
    "  3. Monetária\n",
    "    a. Total gasto, faturamento\n",
    "    b. Alto valor de compra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be61a13",
   "metadata": {},
   "source": [
    "1. Passo 01:\n",
    "  - Ordernar os clientes por Recência\n",
    "\n",
    "2. Passo 02:\n",
    "  - Dividir a base de clientes de acordo com as notas\n",
    "    - Notas de 1 - 5 (5 notas possíveis)\n",
    "    - Divide a base de clientes em 5 grupos de 20% cada\n",
    "    - Quanto menor o valor, maior nota\n",
    "  - Essa nota se chama R Score\n",
    "\n",
    "3. Passo 03:\n",
    "  - Ordernar is clientes pela Frequência\n",
    "\n",
    "4. Passo 04:\n",
    "  - Dar as notas de maneira similar ao passo 02\n",
    "  - Essa nota se chama F Score\n",
    "  - Quanto maior o valor, maior a nota\n",
    "\n",
    "5. Passo 05:\n",
    "  - Ordenar pelo monetário (faturamento)\n",
    "\n",
    "6. Passo 06:\n",
    "  - Dar as notas de maneira similar ao passo 02 e 04\n",
    "  - Essa nota de chama M Score\n",
    "  - Quanto maior o valor, maior a nota\n",
    "\n",
    "7. Passo 07:7\n",
    "  - Calcular a média das notas R,F,M\n",
    "  - RFM Score (pode ordenar por essa média para ter os melhores clientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc5f3b8",
   "metadata": {},
   "source": [
    "Definições que podem ser usadas para dividir os clientes com o RFM e assim direcionar esse clientes para as melhores ações\n",
    "\n",
    "1. Champions\n",
    "  - Compra recentes, frequentes com alto valor gasto\n",
    "  - Prêmios para esses clientes\n",
    "\n",
    "2. Potential Loyalists\n",
    "  - Compras recentes, boa frequência e bom valor gasto\n",
    "  - Programa de Fidelização e Upsell\n",
    "\n",
    "3. New Custumers\n",
    "  - Compra recente, baixa frequência\n",
    "  - Construção de Relacionamento, ofertas especiais\n",
    "\n",
    "4. At Risk Custumers\n",
    "  - \"Faz tempo que não compra\"\n",
    "  - Campanhas de reativação, ofertas, produtos\n",
    "\n",
    "5. Can't Lose Them\n",
    "  - Faz tempo que não compra e não viita o site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce50b2e",
   "metadata": {},
   "source": [
    "Com isso, você consegue entender:\n",
    "\n",
    "1. Quem são seus melhores clientes?\n",
    "\n",
    "2. Quais clientes estão próximos do Churn?\n",
    "\n",
    "3. Quais os potenciais clientes para entrar no programa de Fidelização?\n",
    "\n",
    "4. Quais clientes precisam ser retidos?\n",
    "\n",
    "5. Quais clientes mais prováveis de responder as campanhas de marketing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505c5b4",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 0.0 Início do Projeto </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab41708c",
   "metadata": {},
   "source": [
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas     as pd\n",
    "import numpy      as np\n",
    "import seaborn    as sns\n",
    "import umap.umap_ as umap\n",
    "import re\n",
    "\n",
    "from yellowbrick.cluster   import KElbowVisualizer\n",
    "from yellowbrick.cluster   import SilhouetteVisualizer\n",
    "from IPython.display       import Image\n",
    "from IPython.core.display  import HTML\n",
    "from ydata_profiling       import ProfileReport\n",
    "from sklearn.metrics       import silhouette_score\n",
    "from pathlib               import Path\n",
    "\n",
    "\n",
    "from matplotlib            import pyplot  as plt\n",
    "from sklearn               import cluster as c\n",
    "from sklearn               import metrics as m\n",
    "from sklearn               import preprocessing as pp\n",
    "from sklearn               import decomposition as dd\n",
    "from sklearn               import ensemble as en\n",
    "from sklearn.manifold      import  TSNE \n",
    "from plotly                import express as px\n",
    "\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d929a",
   "metadata": {},
   "source": [
    "## 0.2 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7242a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_settings():\n",
    "    \"\"\"Definições padrões setadas para o uso o Jupyter Notebook.\"\"\"\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    sns.set()\n",
    "\n",
    "#Executando a função\n",
    "jupyter_settings();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e6327",
   "metadata": {},
   "source": [
    "## 0.3 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6483204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dat\n",
    "df_raw = pd.read_csv('../data/Ecommerce/Ecommerce.csv',encoding='unicode_escape')\n",
    "\n",
    "#drop extra column\n",
    "df_raw = df_raw.drop(columns=['Unnamed: 8'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146c0e8",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 1.0 Descrição dos dados </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db094f3",
   "metadata": {},
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18164a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_new = ['invoice_no','stock_code','description','quantity','invoice_date','unit_price','customer_id','country']\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270888c3",
   "metadata": {},
   "source": [
    "## 1.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows {df1.shape[0]}')\n",
    "print(f'Number of cols {df1.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a209e",
   "metadata": {},
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983a8a4",
   "metadata": {},
   "source": [
    "## 1.4 Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe840b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963b940",
   "metadata": {},
   "source": [
    "## 1.5 Replace NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando o que tem NA do que não tem NA\n",
    "df_missing = df1.loc[df1['customer_id'].isna(),:] #Faltando customer\n",
    "df_not_missing = df1.loc[~df1['customer_id'].isna(),:]\n",
    "df_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos ver se esses dados faltando não podem ser opr erro do sistema, buscando o invoice no nos dados não faltando e tentando dar match com os faltantes\n",
    "missing_invoice = df_missing['invoice_no'].drop_duplicates().tolist()\n",
    "df_not_missing.loc[df_not_missing['invoice_no'].isin(missing_invoice),:].head()\n",
    "#Não tem ninguém"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses clientes podem nao ser identificados, por não ter o número de identificador, vamos entrão criar uma identificação para ele, atavés dos invoices no, dessa forma, cada compra diferente seria de um cliente diferente, não da para saber se o mesmo clientes que comprou, pois a priori ele não tem identificação<br><br>\n",
    "Fazendo isso não teria como selecionar esses clientes para o grupo de Insiders, mas também não é interessante perder esses dados, pois, por mais que esses clientes não possam ser selecionados, eles ainda apresentam um comportamento de compras e isso pode influenciar na EDA e na criação de features<br><br>\n",
    "Assim, usando esse dados, eu ganho mais informações para fazer a clusterização e na hora de entregar os clusters eu retiro esses clientes não identificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ni_invoice = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "df_ni_invoice['customer_id'] = np.arange(19000,19000+len(df_ni_invoice),1)\n",
    "\n",
    "#fazendo um merge com o dataframe original\n",
    "df1 = pd.merge(df1,df_ni_invoice,on='invoice_no',how='left')\n",
    "\n",
    "\n",
    "#assim eu tenho duas colunas e preciso que cada as mesmas juntem - coascesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "df1 = df1.drop(columns=['customer_id_x','customer_id_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checando se os NA foram realmente removidos\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867bcfb",
   "metadata": {},
   "source": [
    "## 1.6 Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoice date\n",
    "df1['invoice_date'] = pd.to_datetime(df1['invoice_date'],format='%d-%b-%y')\n",
    "\n",
    "#customer_id\n",
    "df1['customer_id'] = df1['customer_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ad464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando a mudança dos tupos\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcb015",
   "metadata": {},
   "source": [
    "## 1.7 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4662c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_att = df1.select_dtypes(include=['int64','float64'])\n",
    "cat_att = df1.select_dtypes(exclude=['int64','float64','datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae318043",
   "metadata": {},
   "source": [
    "### 1.7.1 Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a679368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#central tendency - média e mediana\n",
    "ct1 = pd.DataFrame(num_att.apply(np.mean)).T\n",
    "ct2 = pd.DataFrame(num_att.apply(np.median)).T\n",
    "\n",
    "#dispersion - desvio padrão, mínimo, máximo, range, skew e kurtosis\n",
    "d1 = pd.DataFrame(num_att.apply(np.std)).T\n",
    "d2 = pd.DataFrame(num_att.apply(np.min)).T\n",
    "d3 = pd.DataFrame(num_att.apply(np.max)).T\n",
    "d4 = pd.DataFrame(num_att.apply(lambda x: x.max() - x.min())).T\n",
    "d5 = pd.DataFrame(num_att.apply(lambda x: x.skew())).T\n",
    "d6 = pd.DataFrame(num_att.apply(lambda x: x.kurtosis())).T\n",
    "\n",
    "#concatenate\n",
    "m = pd.concat([d2,d3,d4,ct1,ct2,d1,d5,d6]).T.reset_index()\n",
    "m.columns = ['attributes','min','max','range','mean','median','std','skew','kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841a8c8",
   "metadata": {},
   "source": [
    "### <font color = 'red'>1.7.1.1 Numerical Attributes - Investigating </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84369e27",
   "metadata": {},
   "source": [
    "1. Quantidade tem valores negativos - Pode ser referente a devoluções\n",
    "\n",
    "2. Preço unitário igual a 0 (pode ser promoção?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a9fb6",
   "metadata": {},
   "source": [
    "### 1.7.2 Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61747e21",
   "metadata": {},
   "source": [
    "#### Invoice No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9994fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problema - Temos Invoice com letras e números\n",
    "#identificação\n",
    "index = cat_att['invoice_no'].apply(lambda x: bool(re.search('[^0-9]+',x)))\n",
    "invoice_no_le = df1.loc[df1['invoice_no'].apply(lambda x: bool(re.search('[^0-9]+',x))),:]\n",
    "linhas_c_letras = invoice_no_le.loc[:,'invoice_no'].count()\n",
    "linhas_c_letras_e_negativas = invoice_no_le.loc[invoice_no_le['quantity'] < 0,'invoice_no'].count()\n",
    "\n",
    "print(f'Há {linhas_c_letras} Invoice No com letras e {linhas_c_letras_e_negativas} tem quantidade negativa {(linhas_c_letras_e_negativas/linhas_c_letras)*100}%')\n",
    "print(f'Todos os Invoices No com letras tem quantidades negativas, podendo ser cancelamentos ou devoluções')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff1814",
   "metadata": {},
   "source": [
    "#### Stock Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525cd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#O Stock Code pode ser letras normalmente, mas quantos tem apenas letras?\n",
    "#Regex seleciona apenas letras do começo ao fim\n",
    "stock_code_le3 = df1.loc[df1['stock_code'].apply(lambda x: bool(re.search('^[a-zA-Z]+$',x))),'stock_code'].count()\n",
    "stock_code_le3\n",
    "print(f'Stock Code just with letters:{stock_code_le3} e as letras são:')\n",
    "cat_att.loc[cat_att['stock_code'].apply(lambda x: bool(re.search('^[a-zA-Z]+$',x))),'stock_code'].unique()\n",
    "\n",
    "#Ação\n",
    "##Rremos ver stock code só com letras -  'POST', 'D', 'M', 'PADS', 'DOT', 'CRUK'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576def1d",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff97c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A descrição não tem algo muito relevante para ajudar a escolher os melhores clientes\n",
    "#Ação\n",
    "##Deletar a coluna  de descrição\n",
    "\n",
    "df1.description.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf29010",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b97e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.country.value_counts(normalize=True).head()*100\n",
    "#Possivelmente será dropada depois, pois ela agrupa muitos dados, e na clusterização preciso de features com alta variancia nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[:,['customer_id','country']].groupby('country').nunique().reset_index().sort_values(by='customer_id',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A maioria das compras, quase 80% são de clientes do Reino Unido, e a maioria dos clietes também são de lá, mostrando assim a predominância dessa features no Reino Unido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af0b9b",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 2.0 Filtragem de Variáveis </font>\n",
    "Filtragem de Variáveis realizada antes da Criação de Features pois as Features são em sua maioria cálculos e com isso, as sujeiras do dataset podem enviesar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd248a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d534091",
   "metadata": {},
   "source": [
    "## Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_code - tirando aqueles que são apenas letras\n",
    "df2 = df2[~df2['stock_code'].isin(['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY',\n",
    "       'DCGSSGIRL', 'PADS', 'B', 'CRUK'])]\n",
    "\n",
    "#description - Não vamos usar por enquanto, pode não ser importante\n",
    "df2 = df2.drop(columns=['description'], axis=1)\n",
    "\n",
    "#country\n",
    "df2 = df2[~df2['country'].isin(['European Community', 'Unspecified'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be1ad3",
   "metadata": {},
   "source": [
    "## Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1efe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit_price - tirando os valores igual a 0 ou muito próximo, pois são produtos que podem ser brindes ou valores muito irrelevantes que não vão nos ajudar a escolher os melhores customers\n",
    "df2 = df2.loc[df2['unit_price'] >= 0.04,:]\n",
    "\n",
    "#quantityh - Dividindo o dataset entre valores de compra e valores de desconto, podendo ser então cancelamentos ou devoluções\n",
    "df2_returns = df2.loc[(df2['quantity'] < 0),:]  #devoluções\n",
    "df2_purchase = df2.loc[(df2['quantity'] > 0),:]  #compras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24739101",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 3.0 Feature Engeneering </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "#Feature Ideais\n",
    "##Moving Average - 7d - 14d\n",
    "##Quantidade de compras por mês em períodos diferentes\n",
    "##Average Financial\n",
    "##Basket Size Price - Preço Médio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ed320",
   "metadata": {},
   "source": [
    "## 3.1 Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Referência\n",
    "df_ref = df3.drop(['invoice_no','stock_code','quantity','invoice_date','unit_price','country'],axis=1).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gross Revenue - Faturamento Bruto - qtde * preço\n",
    "df2_purchase['gross_revenue'] = df2_purchase['quantity'] * df2_purchase['unit_price']\n",
    "\n",
    "#Monetary\n",
    "df_monetary = df2_purchase.loc[:,['customer_id','gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_monetary, on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Recency - Tempo desde a última compra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recency\n",
    "df_recency = df2_purchase.loc[:,['customer_id','invoice_date']].groupby('customer_id').max().reset_index()\n",
    "df_recency['recency_days'] = (df2_purchase['invoice_date'].max() - df_recency['invoice_date']).dt.days #vetoriza a série para aplicar o day\n",
    "df_recency = df_recency[['customer_id','recency_days']].copy()\n",
    "df_ref = pd.merge(df_ref, df_recency, on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Numbers of Purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency\n",
    "df_freq = df2_purchase.loc[:,['customer_id','invoice_no']].groupby('customer_id').nunique().reset_index().rename(columns={'invoice_no' : 'qtde_invoices'})\n",
    "df_ref = pd.merge(df_ref, df_freq,on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Numbers of Itens purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df2_purchase.loc[:,['customer_id','quantity']].groupby('customer_id').sum().reset_index().rename(columns={'quantity' : 'qtde_itens'})\n",
    "df_ref = pd.merge(df_ref, df_freq,on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Numbers of Unique Products purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df2_purchase.loc[:,['customer_id','stock_code']].groupby('customer_id').count().reset_index().rename(columns={'stock_code' : 'qtde_products'})\n",
    "df_ref = pd.merge(df_ref, df_freq,on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 Average Ticket - Ticket Médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_ticket\n",
    "df_tm = df2_purchase.loc[:,['customer_id','gross_revenue']].groupby('customer_id').mean().reset_index().rename(columns={'gross_revenue' : 'avg_ticket'})\n",
    "df_tm['avg_ticket'] = np.round(df_tm['avg_ticket'],2)\n",
    "df_ref = pd.merge(df_ref, df_tm, on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 Average Recency Days - Tempos médio entre compras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df2_purchase.loc[:,['customer_id','invoice_no','invoice_date']].drop_duplicates().sort_values(['customer_id','invoice_no','invoice_date'],ascending=[True,True,True])\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift() #Cria uma coluna deslocada, com se fossem os mesmos dados, uma linhas para baixo\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift()\n",
    "\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply(lambda x: (x['invoice_date'] - x['previous_date']).days if x['customer_id'] == x['next_customer_id'] else np.nan, axis=1)\n",
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_aux.loc[df_aux['customer_id'] == 17850,:]\n",
    "df_aux_calc = df_aux.drop(['invoice_date','next_customer_id','previous_date'],axis=1).dropna()\n",
    "tempo_total_entre_compras = df_aux_calc.loc[:,['customer_id','avg_recency_days']].groupby('customer_id').mean().reset_index()\n",
    "#df_aux2 = pd.merge(total_de_compras,tempo_total_entre_compras,on='customer_id',how='left').reset_index()\n",
    "#df_aux2['avg_recency_days'] = round(df_aux2['time_between_purshases']/df_aux2['invoice_no'],2)\n",
    "df_ref = pd.merge(df_ref, tempo_total_entre_compras, on='customer_id',how='left')\n",
    "df_ref.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.8 Frequency Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = (df2_purchase.loc[:,['customer_id','invoice_no','invoice_date']].drop_duplicates()\n",
    "                                                                         .groupby('customer_id')\n",
    "                                                                         .agg(max_ = ('invoice_date','max'),\n",
    "                                                                              min_ = ('invoice_date','min'),\n",
    "                                                                              compras_ = ('invoice_no','nunique'),\n",
    "                                                                              days_ = ('invoice_date', lambda x: ((x.max() - x.min() ).days)+1))).reset_index()\n",
    "\n",
    "#Frequency per client\n",
    "df_aux['frequency'] = df_aux.loc[:,['compras_','days_']].apply(lambda x: x['compras_'] / x['days_'] if x['days_'] != 0 else 0,axis=1)\n",
    "df_ref = pd.merge(df_ref, df_aux.loc[:,['customer_id','frequency']], on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.9 Quantity of Returns - Devoluções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = df2_returns.loc[:,['customer_id','quantity']].groupby('customer_id').sum().reset_index().rename(columns={'quantity' : 'qtde_returns'})\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns']*(-1)\n",
    "df_returns.head()\n",
    "df_ref = pd.merge(df_ref, df_returns, on='customer_id',how='left')\n",
    "df_ref.loc[df_ref['qtde_returns'].isna(),'qtde_returns'] = 0 #Filtra apenas pelas colunas que tem na nessa coluna e já atribui o zero\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.10 Basket Size - Itens por Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basket size\n",
    "#df_it1 = df2_purchase.loc[:,['customer_id','quantity']].groupby('customer_id').sum().reset_index()\n",
    "#df_it2 = df2_purchase.loc[:,['customer_id','invoice_no']].groupby('customer_id').nunique().reset_index()\n",
    "#df_it = pd.merge(df_it1, df_it2, on='customer_id',how='left')\n",
    "df_it = (df2_purchase.loc[:,['customer_id','invoice_no','quantity']].groupby('customer_id')\n",
    "                                                                         .agg(itens_ = ('quantity','sum'),\n",
    "                                                                              compras_ = ('invoice_no','nunique')\n",
    "                                                                              )).reset_index()\n",
    "df_it['basket_size'] = np.round((df_it['itens_']/df_it['compras_']),2)\n",
    "df_ref = pd.merge(df_ref, df_it.loc[:,['customer_id','basket_size']], on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.11 Unique Basket Size - Itens únicos por Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_it = (df2_purchase.loc[:,['customer_id','invoice_no','stock_code']].groupby('customer_id')\n",
    "                                                                         .agg(itens_ = ('stock_code','count'),\n",
    "                                                                              compras_ = ('invoice_no','nunique')\n",
    "                                                                              )).reset_index()\n",
    "df_it['u_basket_size'] = np.round((df_it['itens_']/df_it['compras_']),2)\n",
    "df_ref = pd.merge(df_ref, df_it.loc[:,['customer_id','u_basket_size']], on='customer_id',how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a593c5e",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 4.0 EDA (Exploratory Data Analysis) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f433e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_ref.dropna().copy()\n",
    "df4.isna().sum()\n",
    "#Objetivo de entender as features e seus comportamentos\n",
    "#Sempre olhar os outliers, ver se é realmente isso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Univariate Analysis\n",
    "Feita para tirar a sugeira e ver se o que está indo para o modelo está correto e coerente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Da uma ideia de como as variáveis estão\n",
    "#Embeding - Espaço diferente do original, que pode ser mais organizado, rodamos assim o algoritmo em cima desse espaço mais organizado\n",
    "#É basicamente uma feature engeneering, que transforma a feature e auxilia na organização  dos dado\n",
    "\n",
    "out_dir = Path(\"insiders_loyalty_program\") / \"reports\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)  # garante a pasta\n",
    "\n",
    "out_file = out_dir / \"report_v1.html\"\n",
    "\n",
    "profile = ProfileReport(df4)\n",
    "profile.to_file(out_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O que olhamos no report relacionado com o problema de clusterização?\n",
    "1. Clusters Coesos - Separados\n",
    "2. Tipo do Cluster Varia de Acordo com o modelo de negócio - No modelo atual é mais difícil encontrar o clusters separados - As compras tem várias faixas de preço e muito próximas\n",
    "  Assim, para a clusterização procuramos colunas com variabilidade\n",
    "  Métricas que indicam isso:\n",
    "  - Min, Max, Range (Dispersão)\n",
    "  - Média e Mediana (Se forem iguais, não tem outliers)\n",
    "  - Desvio Padrão e Variância (Um desvio padrão alto significa que na média os meus pontos estão distantes do centro, se for baixo, eles estão próximos)\n",
    "  - Coeficiente de Variação (Desvio padrão / Média - Se tem um valor menor, significa que ele tem a chance maior de ter um retorno próximo a média) - Isso pode ser usado com colunas diferentes e comparar elas com relação a variação\n",
    "  - Distribuição\n",
    "\n",
    "**NOTAS**\n",
    "\n",
    "Kurtosis - Quanto maior o valor, mais pontudo é a distribuição, se for próxima de uma normal ou for uniforme, o valor é menor.\n",
    "Concentração de pontos em uma área\n",
    "Skewness - O quão deslocada essa ponta é com relação a madiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTAS ANALISE UNIVARIADA**\n",
    "Analisar se ver se o que o maior valor é muito diferente do segundo maior valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[df4['gross_revenue'] >= 279138.02,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df4['gross_revenue'], binwidth=7);\n",
    "#bins - Divisão do eixo x no histplot (Determina a quantidade de separaçãoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Quantidade de Itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[df4['qtde_itens'] >= 196844,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Quantidade de Produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[df4['qtde_products'] >= 7838,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Avg Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[df4['avg_ticket'] >= 56157.5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[df3['customer_id'] == 16446,:]\n",
    "#Esse cliente devolveu quase tudo o que comprou\n",
    "#Será que não vale a pena repensar e não dividir o dataser entre compra e devoluções e deixar eles se anularem para que as compras dos clientes façam sentido em questão de saldo final????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Bivariate Analysis\n",
    "Classificação e Regressão - Sempre a correlação entre a variável e a minha variável resposta<br>\n",
    "Clusterização - Procurar Features que juntas criem grupos que sejam coesos e distantes entre si e tirar aquelas que não formam clusters de jeito nenhum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Princípio do SVM - Mudar o espaço dos dados de forma que fique mais fácil do algotimo separar os dados e com isso fazer a predição com mais aertabilidade\n",
    "#Cria um espaço de dados mais organiado e treina a partir dele\n",
    "#Espaço de embeeding\n",
    "#PROCURAR MAIS SOBRE ISSO\n",
    "\n",
    "cols = ['customer_id']\n",
    "df4_2 = df4.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(25,12) )\n",
    "sns.pairplot(df4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Estudo do Espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df43 = df4.drop(columns=['customer_id'],axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = pp.MinMaxScaler()\n",
    "\n",
    "df43['gross_revenue'] = mm.fit_transform(df43[['gross_revenue']])\n",
    "df43['recency_days'] = mm.fit_transform(df43[['recency_days']])\n",
    "df43['qtde_invoices'] = mm.fit_transform(df43[['qtde_invoices']])\n",
    "df43['qtde_itens'] = mm.fit_transform(df43[['qtde_itens']])\n",
    "df43['qtde_products'] = mm.fit_transform(df43[['qtde_products']])\n",
    "df43['avg_ticket'] = mm.fit_transform(df43[['avg_ticket']])\n",
    "df43['avg_recency_days'] = mm.fit_transform(df43[['avg_recency_days']])\n",
    "df43['frequency'] = mm.fit_transform(df43[['frequency']])\n",
    "df43['qtde_returns'] = mm.fit_transform(df43[['qtde_returns']])\n",
    "df43['basket_size'] = mm.fit_transform(df43[['basket_size']])\n",
    "df43['u_basket_size'] = mm.fit_transform(df43[['u_basket_size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df43.copy()\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = dd.PCA(n_components = X.shape[1])\n",
    "\n",
    "principal_components = pca.fit_transform(X)\n",
    "\n",
    "#plot explained variable\n",
    "features = range(pca.n_components_) #Definindo o espaço do número de componentes\n",
    "\n",
    "plt.bar(features,pca.explained_variance_ratio_,color='black')\n",
    "\n",
    "#Componentes principais com a maior variação de dados\n",
    "\n",
    "df_pca = pd.DataFrame(principal_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=0,y=1,data=df_pca);\n",
    "\n",
    "#Vamos que pelo fato dessas variáveis gerarem variação nos dados, não nos da muitas divisões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state = 42)\n",
    "embedding = reducer.fit_transform (X)\n",
    "\n",
    "#embedding\n",
    "df_pca['embedding_x'] = embedding[:,0]\n",
    "df_pca['embedding_y'] = embedding[:,1]\n",
    "\n",
    "#plot UMAP\n",
    "sns.scatterplot(x='embedding_x', y='embedding_y',data=df_pca);\n",
    "\n",
    "#Sem muitras definições a partir disso também"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = TSNE(random_state = 42,n_components = 2,n_jobs = -1)\n",
    "embedding = reducer.fit_transform (X)\n",
    "\n",
    "#embedding\n",
    "df_pca['embedding_x'] = embedding[:,0]\n",
    "df_pca['embedding_y'] = embedding[:,1]\n",
    "\n",
    "#plot UMAP\n",
    "sns.scatterplot(x='embedding_x', y='embedding_y',data=df_pca);\n",
    "\n",
    "#Sem muitras definições a partir disso também"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Tree_Based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A ideia é definir uma feature que achamos importante, como o Gross Revenue, como a variável resposta, colocar uma árvore, gerar as folhas com isso o espaço de embedding\n",
    "\n",
    "#training dataset\n",
    "cols = ['customer_id','gross_revenue']\n",
    "X = df4.drop(cols,axis=1)\n",
    "y = df4['gross_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "rf_model = en.RandomForestRegressor(n_estimators = 100,random_state=42)\n",
    "\n",
    "#model traing\n",
    "rf_model.fit(X,y)\n",
    "\n",
    "#Leaf\n",
    "df_leaf = pd.DataFrame(rf_model.apply(X)) #Mostra a decisão de cada folha para cada cliente, mostrando a posição (index) da folha que cada costumer_id caiu naquela árvore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando o redutor de dimensionalidade\n",
    "reducer = umap.UMAP(random_state = 42)\n",
    "embedding = reducer.fit_transform (df_leaf) #Projeção das 100 colunas em apenas duas\n",
    "\n",
    "#embedding\n",
    "df_pca['embedding_x'] = embedding[:,0]\n",
    "df_pca['embedding_y'] = embedding[:,1]\n",
    "\n",
    "#plot UMAP\n",
    "sns.scatterplot(x='embedding_x', y='embedding_y',data=df_pca);\n",
    "\n",
    "#Não consigo explicar o motivo dos clientes erem vizinhos\n",
    "#Contudo, cria os clusters de maneira muito acertiva e baseada no gross revenue\n",
    "#Não precisa necessariamente diminuir para 2 variáveis, pode ser para 3 ou 4, mesmo nãos endo visível tende a organizar bem o espaço\n",
    "\n",
    "#Usado em qualquer tipo de projeto de Ciência de Dados\n",
    "#A ideia é que antes de começar a testar os modelos, mas depois de já ter feito a criação de features, seleção de features e preparação das mesmas, você use uma árvore para treinar o modelo, mas ao invés de classificar com o modelo treinado, gera as folhas para gerar um novo espaço, com isso, ou reduz a dimensionalidade para rodar em cima ou classifica em cima das folhas\n",
    "#Podendo fazer assim uma regressão em cima do Embedding, onde o X seria o df_leaf eo meu y a variável resposta que já quero prever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_test = df_pca.loc[:,['embedding_x','embedding_y']]\n",
    "df_for_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d7fb4",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 5.0 Data Preparation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5= df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a370658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A distribuição está muito longe da nromal, mas mesmo assim iremos tentar o Standard Scaler\n",
    "ss = pp.StandardScaler() #Mantem a distribuição, e apenas rescala os dados\n",
    "\n",
    "df5['gross_revenue'] = ss.fit_transform(df5[['gross_revenue']])\n",
    "df5['recency_days'] = ss.fit_transform(df5[['recency_days']])\n",
    "df5['qtde_invoices'] = ss.fit_transform(df5[['qtde_invoices']])\n",
    "df5['qtde_itens'] = ss.fit_transform(df5[['qtde_itens']])\n",
    "df5['qtde_products'] = ss.fit_transform(df5[['qtde_products']])\n",
    "df5['avg_ticket'] = ss.fit_transform(df5[['avg_ticket']])\n",
    "df5['avg_recency_days'] = ss.fit_transform(df5[['avg_recency_days']])\n",
    "df5['frequency'] = ss.fit_transform(df5[['frequency']])\n",
    "df5['qtde_returns'] = ss.fit_transform(df5[['qtde_returns']])\n",
    "df5['basket_size'] = ss.fit_transform(df5[['basket_size']])\n",
    "df5['u_basket_size'] = ss.fit_transform(df5[['u_basket_size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0885ebb",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 6.0 Feature Selection </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df_for_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd625558",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 7.0 Hyperparameter Fine-Tunning </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ffc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7 = df6.drop(columns=['customer_id'])\n",
    "df7 = df6.copy()\n",
    "clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862b3b4",
   "metadata": {},
   "source": [
    "## 7.1 Within-Cluster Sum of Square (WSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3209b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KElbowVisualizer(c.KMeans(),k=clusters,timings=False)\n",
    "kmeans.fit(df7)\n",
    "kmeans.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc236d",
   "metadata": {},
   "source": [
    "## 7.2 Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KElbowVisualizer(c.KMeans(),k=clusters,timings=False,metric='silhouette')\n",
    "kmeans.fit(df7)\n",
    "kmeans.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4a1a0",
   "metadata": {},
   "source": [
    "## 7.3 Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7,2,figsize = (50,36))\n",
    "\n",
    "for k in clusters:\n",
    "  km = c.KMeans(init='random',n_clusters=k,n_init=10,max_iter=100,random_state=42);\n",
    "  q, mod = divmod(k,2) #2 é o mínimo\n",
    "  vs = SilhouetteVisualizer(km,colors='yellowbrick',ax=ax[q-1][mod]);\n",
    "  vs.fit(df7);\n",
    "  vs.finalize();\n",
    "\n",
    "#A visualização das silhetas não ficou boa pois um cluster fica muito maior que os outros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3631e",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 8.0 Model Training </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12194762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df7.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd7e8f",
   "metadata": {},
   "source": [
    "## 8.1 K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=6 #definido\n",
    "#model definition\n",
    "kmeans = c.KMeans(init='random',n_clusters=k,n_init=10,max_iter=300,random_state=42)\n",
    "#model training\n",
    "kmeans.fit(df8)\n",
    "#validation\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ab3c8",
   "metadata": {},
   "source": [
    "## 8.2 Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSS (Within-Cluster Sum of Square)\n",
    "print(f'WSS value: {kmeans.inertia_}')\n",
    "\n",
    "# SS (Silhouette Score)\n",
    "\n",
    "print('SS value: {}'.format(silhouette_score(df8,labels,metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a3911",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 9.0 Cluster Analysis </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df6.copy()\n",
    "df9['cluster'] = labels\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd67bdcf",
   "metadata": {},
   "source": [
    "## 9.1 Visualization Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = SilhouetteVisualizer(kmeans,colors='yellowbrick');\n",
    "vs.fit(df8);\n",
    "vs.finalize();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='embedding_x',y='embedding_y',data=df9,hue='cluster',palette=sns.color_palette('hls',n_colors=len(df9['cluster'].unique())));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf915356",
   "metadata": {},
   "source": [
    "## 9.2 2d Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43281a37",
   "metadata": {},
   "source": [
    "Quais features estão bagunçando mais do que organizando os dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = df9.copy()\n",
    "#sns.pairplot(df_viz,hue='cluster')\n",
    "\n",
    "#Os dados estão muito embolados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b73279",
   "metadata": {},
   "source": [
    "## 9.3 UMAP\n",
    "Abordagem por topologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c170927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com o encodind\n",
    "\n",
    "reducer = umap.UMAP(random_state = 42,n_neighbors=80)\n",
    "embedding = reducer.fit_transform (df9)\n",
    "\n",
    "#embedding\n",
    "df_viz['embedding_x'] = embedding[:,0]\n",
    "df_viz['embedding_y'] = embedding[:,1]\n",
    "\n",
    "#plot UMAP\n",
    "sns.scatterplot(x='embedding_x', y='embedding_y',hue='cluster',palette=sns.color_palette('hls',n_colors=len(df_viz['cluster'].unique())),\n",
    "                data=df_viz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sem o encodind\n",
    "\n",
    "reducer = umap.UMAP(random_state = 42,n_neighbors=40)\n",
    "embedding = reducer.fit_transform (df8)\n",
    "\n",
    "#embedding\n",
    "df_viz['embedding_x'] = embedding[:,0]\n",
    "df_viz['embedding_y'] = embedding[:,1]\n",
    "\n",
    "#plot UMAP\n",
    "sns.scatterplot(x='embedding_x', y='embedding_y',hue='cluster',palette=sns.color_palette('hls',n_colors=len(df_viz['cluster'].unique())),\n",
    "                data=df_viz);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa66a5b",
   "metadata": {},
   "source": [
    "## 9.4 Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abeb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of customer\n",
    "df_cluster = df9.loc[:,['customer_id','cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['perc_customer'] = round((df_cluster['customer_id'] / df_cluster['customer_id'].sum())*100,2)\n",
    "\n",
    "#Avg Gross revenue\n",
    "df_avg_gr = df9.loc[:,['gross_revenue','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_gr,how='inner',on='cluster')\n",
    "\n",
    "#Avg recency days\n",
    "df_avg_rd = df9.loc[:,['recency_days','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_rd,how='inner',on='cluster')\n",
    "\n",
    "#Avg invoice_no\n",
    "df_avg_in = df9.loc[:,['invoice_no','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_in,how='inner',on='cluster')\n",
    "df_cluster\n",
    "\n",
    "#Avg_ticket \n",
    "df_avg_tkt = df9.loc[:,['avg_ticket','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_tkt,how='inner',on='cluster')\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78344162",
   "metadata": {},
   "source": [
    "# <font color = \"red\"> 10.0 Deploy do Production </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a64931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7beaeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
